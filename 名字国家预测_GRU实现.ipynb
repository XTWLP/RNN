{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "名字国家预测 GRU实现.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XTWLP/RNN/blob/main/%E5%90%8D%E5%AD%97%E5%9B%BD%E5%AE%B6%E9%A2%84%E6%B5%8B_GRU%E5%AE%9E%E7%8E%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5I50Fe6xzFn"
      },
      "source": [
        "import gzip\n",
        "import csv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import math\n",
        "\n",
        "class NameDataset(Dataset):\n",
        "    def __init__(self, is_train_set=True):\n",
        "        filename = 'names_train.csv.gz' if is_train_set else 'names_test.csv.gz'\n",
        "        with gzip.open(filename, 'rt') as f:\n",
        "            reader = csv.reader(f)\n",
        "            rows = list(reader)\n",
        "        self.names = [row[0] for row in rows]\n",
        "        self.len = len(self.names)\n",
        "        self.countries = [row[1] for row in rows]\n",
        "        self.country_list = list(sorted(set(self.countries)))\n",
        "        self.country_dict = self.getCountryDict()\n",
        "        self.country_num = len(self.country_list)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.names[index], self.country_dict[self.countries[index]]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "    \n",
        "    def getCountryDict(self):\n",
        "        country_dict = dict()\n",
        "        for idx, country_name in enumerate(self.country_list, 0):\n",
        "            country_dict[country_name] = idx\n",
        "        return country_dict\n",
        "    \n",
        "    def idx2country(self, index):\n",
        "        return self.country_list[index]\n",
        "    \n",
        "    def getCountriesNum(self):\n",
        "        return self.country_num"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FL4kTz1sxzFw"
      },
      "source": [
        "class RNNClassifier(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, n_layers=1, bidirectional=True):\n",
        "            super(RNNClassifier, self).__init__()\n",
        "            self.hidden_size = hidden_size\n",
        "            self.n_layers = n_layers\n",
        "            self.n_directions = 2 if bidirectional else 1\n",
        "            \n",
        "            self.embedding = torch.nn.Embedding(input_size, hidden_size)\n",
        "            self.gru = torch.nn.GRU(hidden_size, hidden_size, n_layers,\n",
        "                                    bidirectional=bidirectional)\n",
        "            self.fc = torch.nn.Linear(hidden_size * self.n_directions, output_size)\n",
        "    \n",
        "    def _init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.n_layers * self.n_directions,\n",
        "                            batch_size, self.hidden_size)\n",
        "        return create_tensor(hidden)\n",
        "    def forward(self, input, seq_lengths):\n",
        "        # input shape : B x S -> S x B\n",
        "        input = input.t()\n",
        "        batch_size = input.size(1)\n",
        "        \n",
        "        hidden = self._init_hidden(batch_size)\n",
        "        embedding = self.embedding(input)\n",
        "        \n",
        "        # pack them up\n",
        "        gru_input = nn.utils.rnn.pack_padded_sequence(embedding, seq_lengths)\n",
        "        \n",
        "        output, hidden = self.gru(gru_input, hidden)\n",
        "        if self.n_directions == 2:\n",
        "            hidden_cat = torch.cat([hidden[-1], hidden[-2]], dim=1)\n",
        "        else:\n",
        "            hidden_cat = hidden[-1]\n",
        "        fc_output = self.fc(hidden_cat)\n",
        "        return fc_output"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LcYVO-7xzF1"
      },
      "source": [
        "def name2list(name):\n",
        "    arr = [ord(c) for c in name]\n",
        "    return arr, len(arr)\n",
        "\n",
        "def create_tensor(tensor):\n",
        "    if USE_GPU:\n",
        "        device = torch.device(\"cuda:0\")\n",
        "        tensor = tensor.to(device)\n",
        "    return tensor"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMnhy2qExzF9"
      },
      "source": [
        "def make_tensors(names, countries):\n",
        "        sequences_and_lengths = [name2list(name) for name in names]\n",
        "        name_sequences = [sl[0] for sl in sequences_and_lengths]\n",
        "        seq_lengths = torch.LongTensor([sl[1] for sl in sequences_and_lengths])\n",
        "        countries = countries.long()\n",
        "\n",
        "        # make tensor of name, BatchSize x SeqLen\n",
        "        seq_tensor = torch.zeros(len(name_sequences), seq_lengths.max()).long()\n",
        "        for idx, (seq, seq_len) in enumerate(zip(name_sequences, seq_lengths), 0):\n",
        "            seq_tensor[idx, :seq_len] = torch.LongTensor(seq)\n",
        "       \n",
        "        # sort by length to use pack_padded_sequence\n",
        "        seq_lengths, perm_idx = seq_lengths.sort(dim=0, descending=True)\n",
        "        seq_tensor = seq_tensor[perm_idx]\n",
        "        countries = countries[perm_idx]\n",
        "        \n",
        "        return create_tensor(seq_tensor), \\\n",
        "                create_tensor(seq_lengths),\\\n",
        "                create_tensor(countries)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQatyF3lxzGC"
      },
      "source": [
        "def trainModel():\n",
        "    total_loss = 0\n",
        "    for i, (names, countries) in enumerate(trainloader, 1):\n",
        "        inputs, seq_lengths, target = make_tensors(names, countries)\n",
        "        output = classifier(inputs, seq_lengths)\n",
        "        loss = criterion(output, target)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        if i % 10 == 0:\n",
        "            print(f'[{time_since(start)}] Epoch {epoch} ', end='')\n",
        "            print(f'[{i * len(inputs)}/{len(trainset)}] ', end='')\n",
        "            print(f'loss={total_loss / (i * len(inputs))}')\n",
        "    return total_loss"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v64DBM-cxzGJ"
      },
      "source": [
        "def testModel():\n",
        "    correct = 0\n",
        "    total = len(testset)\n",
        "    print(\"evaluating trained model ...\")\n",
        "    with torch.no_grad():\n",
        "        for i, (names, countries) in enumerate(testloader, 1):\n",
        "            inputs, seq_lengths, target = make_tensors(names, countries)\n",
        "            output = classifier(inputs, seq_lengths)\n",
        "            pred = output.max(dim=1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    \n",
        "        percent = '%.2f' % (100 * correct / total)\n",
        "        print(f'Test set: Accuracy {correct}/{total} {percent}%')\n",
        "    \n",
        "    return correct / total"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX_ruNRAxzGQ"
      },
      "source": [
        "# Parameters\n",
        "HIDDEN_SIZE = 100\n",
        "BATCH_SIZE = 256\n",
        "N_LAYER = 2\n",
        "N_EPOCHS = 100\n",
        "N_CHARS = 128\n",
        "USE_GPU = True\n",
        "\n",
        "trainset = NameDataset(is_train_set=True)\n",
        "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "testset = NameDataset(is_train_set=False)\n",
        "testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "N_COUNTRY = trainset.getCountriesNum()\n",
        "\n",
        "def time_since(since):\n",
        "    s = time.time() - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTVl4hMixzGW",
        "outputId": "ab3ec710-aac7-445c-8237-3060b399094f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import time as time\n",
        "if __name__ == '__main__':\n",
        "    classifier = RNNClassifier(N_CHARS, HIDDEN_SIZE, N_COUNTRY, N_LAYER)\n",
        "    if USE_GPU:\n",
        "        device = torch.device(\"cuda:0\")\n",
        "        classifier.to(device)\n",
        "        \n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
        "    \n",
        "    start = time.time()\n",
        "    print(\"Training for %d epochs...\" % N_EPOCHS)\n",
        "    acc_list = []\n",
        "    for epoch in range(1, N_EPOCHS + 1):\n",
        "        # Train cycle\n",
        "        trainModel()\n",
        "        acc = testModel()\n",
        "        acc_list.append(acc)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training for 100 epochs...\n",
            "[0m 0s] Epoch 1 [2560/13374] loss=0.008834093902260065\n",
            "[0m 0s] Epoch 1 [5120/13374] loss=0.007601227215491235\n",
            "[0m 0s] Epoch 1 [7680/13374] loss=0.006888123663763205\n",
            "[0m 1s] Epoch 1 [10240/13374] loss=0.006424045329913497\n",
            "[0m 1s] Epoch 1 [12800/13374] loss=0.006034118365496397\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 4482/6700 66.90%\n",
            "[0m 1s] Epoch 2 [2560/13374] loss=0.004199231998063624\n",
            "[0m 1s] Epoch 2 [5120/13374] loss=0.004115872329566628\n",
            "[0m 1s] Epoch 2 [7680/13374] loss=0.003932726235749821\n",
            "[0m 2s] Epoch 2 [10240/13374] loss=0.0038536084757652134\n",
            "[0m 2s] Epoch 2 [12800/13374] loss=0.0038170763384550808\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 4910/6700 73.28%\n",
            "[0m 2s] Epoch 3 [2560/13374] loss=0.003216644446365535\n",
            "[0m 2s] Epoch 3 [5120/13374] loss=0.0031325454358011482\n",
            "[0m 3s] Epoch 3 [7680/13374] loss=0.003081915038637817\n",
            "[0m 3s] Epoch 3 [10240/13374] loss=0.003063576709246263\n",
            "[0m 3s] Epoch 3 [12800/13374] loss=0.0030026989988982677\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5236/6700 78.15%\n",
            "[0m 3s] Epoch 4 [2560/13374] loss=0.0026986158918589354\n",
            "[0m 4s] Epoch 4 [5120/13374] loss=0.0026132835890166463\n",
            "[0m 4s] Epoch 4 [7680/13374] loss=0.0026130847555274764\n",
            "[0m 4s] Epoch 4 [10240/13374] loss=0.0025755639420822264\n",
            "[0m 4s] Epoch 4 [12800/13374] loss=0.002552650081925094\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5390/6700 80.45%\n",
            "[0m 5s] Epoch 5 [2560/13374] loss=0.0022084758849814532\n",
            "[0m 5s] Epoch 5 [5120/13374] loss=0.0022256329306401313\n",
            "[0m 5s] Epoch 5 [7680/13374] loss=0.0022278500720858572\n",
            "[0m 5s] Epoch 5 [10240/13374] loss=0.002222468698164448\n",
            "[0m 5s] Epoch 5 [12800/13374] loss=0.00222704045008868\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5434/6700 81.10%\n",
            "[0m 6s] Epoch 6 [2560/13374] loss=0.001929666323121637\n",
            "[0m 6s] Epoch 6 [5120/13374] loss=0.0019258509331848473\n",
            "[0m 6s] Epoch 6 [7680/13374] loss=0.001919712929520756\n",
            "[0m 6s] Epoch 6 [10240/13374] loss=0.0019778077985392883\n",
            "[0m 6s] Epoch 6 [12800/13374] loss=0.0019760577962733804\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5488/6700 81.91%\n",
            "[0m 7s] Epoch 7 [2560/13374] loss=0.001812294393312186\n",
            "[0m 7s] Epoch 7 [5120/13374] loss=0.0018116127757821232\n",
            "[0m 7s] Epoch 7 [7680/13374] loss=0.0017967172587911287\n",
            "[0m 7s] Epoch 7 [10240/13374] loss=0.0017888840229716152\n",
            "[0m 7s] Epoch 7 [12800/13374] loss=0.0018017695960588754\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5581/6700 83.30%\n",
            "[0m 8s] Epoch 8 [2560/13374] loss=0.0016691978788003325\n",
            "[0m 8s] Epoch 8 [5120/13374] loss=0.0015947902342304588\n",
            "[0m 8s] Epoch 8 [7680/13374] loss=0.0016652853266956905\n",
            "[0m 8s] Epoch 8 [10240/13374] loss=0.0016483574028825388\n",
            "[0m 8s] Epoch 8 [12800/13374] loss=0.0016295643686316907\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5600/6700 83.58%\n",
            "[0m 9s] Epoch 9 [2560/13374] loss=0.0014258758630603552\n",
            "[0m 9s] Epoch 9 [5120/13374] loss=0.001416804062318988\n",
            "[0m 9s] Epoch 9 [7680/13374] loss=0.0014303795353043825\n",
            "[0m 9s] Epoch 9 [10240/13374] loss=0.0014600809852709062\n",
            "[0m 10s] Epoch 9 [12800/13374] loss=0.0014630704757291823\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5606/6700 83.67%\n",
            "[0m 10s] Epoch 10 [2560/13374] loss=0.0012215737951919436\n",
            "[0m 10s] Epoch 10 [5120/13374] loss=0.0013137569825630636\n",
            "[0m 10s] Epoch 10 [7680/13374] loss=0.0013141139099995295\n",
            "[0m 11s] Epoch 10 [10240/13374] loss=0.0013159732858184724\n",
            "[0m 11s] Epoch 10 [12800/13374] loss=0.0013328036363236607\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5628/6700 84.00%\n",
            "[0m 11s] Epoch 11 [2560/13374] loss=0.001165228057652712\n",
            "[0m 11s] Epoch 11 [5120/13374] loss=0.0011488328746054322\n",
            "[0m 11s] Epoch 11 [7680/13374] loss=0.0011712317975858847\n",
            "[0m 12s] Epoch 11 [10240/13374] loss=0.0012060406239470466\n",
            "[0m 12s] Epoch 11 [12800/13374] loss=0.0011958521837368606\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5638/6700 84.15%\n",
            "[0m 12s] Epoch 12 [2560/13374] loss=0.0010991006216499954\n",
            "[0m 12s] Epoch 12 [5120/13374] loss=0.0010623492329614238\n",
            "[0m 13s] Epoch 12 [7680/13374] loss=0.0010952675191219896\n",
            "[0m 13s] Epoch 12 [10240/13374] loss=0.001087684826052282\n",
            "[0m 13s] Epoch 12 [12800/13374] loss=0.0010873711796011776\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5670/6700 84.63%\n",
            "[0m 13s] Epoch 13 [2560/13374] loss=0.000919597694883123\n",
            "[0m 13s] Epoch 13 [5120/13374] loss=0.000922057672869414\n",
            "[0m 14s] Epoch 13 [7680/13374] loss=0.0009636322502046824\n",
            "[0m 14s] Epoch 13 [10240/13374] loss=0.0009703844101750292\n",
            "[0m 14s] Epoch 13 [12800/13374] loss=0.0009685852960683405\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5667/6700 84.58%\n",
            "[0m 14s] Epoch 14 [2560/13374] loss=0.0008240375260356814\n",
            "[0m 15s] Epoch 14 [5120/13374] loss=0.0008445927815046161\n",
            "[0m 15s] Epoch 14 [7680/13374] loss=0.00084234841245537\n",
            "[0m 15s] Epoch 14 [10240/13374] loss=0.0008652535121655092\n",
            "[0m 15s] Epoch 14 [12800/13374] loss=0.0008533590217120945\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5658/6700 84.45%\n",
            "[0m 16s] Epoch 15 [2560/13374] loss=0.0007471769291441888\n",
            "[0m 16s] Epoch 15 [5120/13374] loss=0.0007333670451771468\n",
            "[0m 16s] Epoch 15 [7680/13374] loss=0.0007166360427315037\n",
            "[0m 16s] Epoch 15 [10240/13374] loss=0.0007336997019592673\n",
            "[0m 16s] Epoch 15 [12800/13374] loss=0.000756575521081686\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5698/6700 85.04%\n",
            "[0m 17s] Epoch 16 [2560/13374] loss=0.0006507542391773313\n",
            "[0m 17s] Epoch 16 [5120/13374] loss=0.0006511966639664024\n",
            "[0m 17s] Epoch 16 [7680/13374] loss=0.000655492371879518\n",
            "[0m 17s] Epoch 16 [10240/13374] loss=0.0006774218200007454\n",
            "[0m 17s] Epoch 16 [12800/13374] loss=0.0006837898667436094\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5656/6700 84.42%\n",
            "[0m 18s] Epoch 17 [2560/13374] loss=0.0005605433310847729\n",
            "[0m 18s] Epoch 17 [5120/13374] loss=0.0005626252881484106\n",
            "[0m 18s] Epoch 17 [7680/13374] loss=0.0005621071274314696\n",
            "[0m 18s] Epoch 17 [10240/13374] loss=0.0005812145107483957\n",
            "[0m 18s] Epoch 17 [12800/13374] loss=0.0006040312926052138\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5655/6700 84.40%\n",
            "[0m 19s] Epoch 18 [2560/13374] loss=0.000496412196662277\n",
            "[0m 19s] Epoch 18 [5120/13374] loss=0.00049826483882498\n",
            "[0m 19s] Epoch 18 [7680/13374] loss=0.0004961861025852462\n",
            "[0m 19s] Epoch 18 [10240/13374] loss=0.0005083283271233085\n",
            "[0m 20s] Epoch 18 [12800/13374] loss=0.0005327566160121933\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5664/6700 84.54%\n",
            "[0m 20s] Epoch 19 [2560/13374] loss=0.0004482984251808375\n",
            "[0m 20s] Epoch 19 [5120/13374] loss=0.0004389649198856205\n",
            "[0m 20s] Epoch 19 [7680/13374] loss=0.00045911154884379355\n",
            "[0m 20s] Epoch 19 [10240/13374] loss=0.00046837393238092774\n",
            "[0m 21s] Epoch 19 [12800/13374] loss=0.0004736758297076449\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5647/6700 84.28%\n",
            "[0m 21s] Epoch 20 [2560/13374] loss=0.0003782666404731572\n",
            "[0m 21s] Epoch 20 [5120/13374] loss=0.00039514523814432323\n",
            "[0m 21s] Epoch 20 [7680/13374] loss=0.00040070397565917425\n",
            "[0m 22s] Epoch 20 [10240/13374] loss=0.0004009231175587047\n",
            "[0m 22s] Epoch 20 [12800/13374] loss=0.0004131866066018119\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5628/6700 84.00%\n",
            "[0m 22s] Epoch 21 [2560/13374] loss=0.0003723565983818844\n",
            "[0m 22s] Epoch 21 [5120/13374] loss=0.00037134604208404197\n",
            "[0m 22s] Epoch 21 [7680/13374] loss=0.0003848779742838815\n",
            "[0m 23s] Epoch 21 [10240/13374] loss=0.00038926195484236816\n",
            "[0m 23s] Epoch 21 [12800/13374] loss=0.00039295618829783053\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5635/6700 84.10%\n",
            "[0m 23s] Epoch 22 [2560/13374] loss=0.0003118136402918026\n",
            "[0m 23s] Epoch 22 [5120/13374] loss=0.0003262951722717844\n",
            "[0m 24s] Epoch 22 [7680/13374] loss=0.00034111741406377404\n",
            "[0m 24s] Epoch 22 [10240/13374] loss=0.00035284904806758276\n",
            "[0m 24s] Epoch 22 [12800/13374] loss=0.000358739176299423\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5643/6700 84.22%\n",
            "[0m 24s] Epoch 23 [2560/13374] loss=0.00031432425166713076\n",
            "[0m 24s] Epoch 23 [5120/13374] loss=0.00032734609994804486\n",
            "[0m 25s] Epoch 23 [7680/13374] loss=0.0003349438411532901\n",
            "[0m 25s] Epoch 23 [10240/13374] loss=0.000345008463045815\n",
            "[0m 25s] Epoch 23 [12800/13374] loss=0.000349131976836361\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5640/6700 84.18%\n",
            "[0m 25s] Epoch 24 [2560/13374] loss=0.0002367410095757805\n",
            "[0m 26s] Epoch 24 [5120/13374] loss=0.0002802219278237317\n",
            "[0m 26s] Epoch 24 [7680/13374] loss=0.000291594494774472\n",
            "[0m 26s] Epoch 24 [10240/13374] loss=0.0003038651615497656\n",
            "[0m 26s] Epoch 24 [12800/13374] loss=0.00031525880185654385\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5628/6700 84.00%\n",
            "[0m 27s] Epoch 25 [2560/13374] loss=0.0002298078004969284\n",
            "[0m 27s] Epoch 25 [5120/13374] loss=0.00025622372777434066\n",
            "[0m 27s] Epoch 25 [7680/13374] loss=0.00027472905203467234\n",
            "[0m 27s] Epoch 25 [10240/13374] loss=0.000286771112223505\n",
            "[0m 27s] Epoch 25 [12800/13374] loss=0.00029165751620894296\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5626/6700 83.97%\n",
            "[0m 28s] Epoch 26 [2560/13374] loss=0.0002713834648602642\n",
            "[0m 28s] Epoch 26 [5120/13374] loss=0.00026501040993025525\n",
            "[0m 28s] Epoch 26 [7680/13374] loss=0.0002639868961220297\n",
            "[0m 28s] Epoch 26 [10240/13374] loss=0.0002747871203609975\n",
            "[0m 28s] Epoch 26 [12800/13374] loss=0.0002830275293672457\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5636/6700 84.12%\n",
            "[0m 29s] Epoch 27 [2560/13374] loss=0.00020348621474113314\n",
            "[0m 29s] Epoch 27 [5120/13374] loss=0.00022827178763691337\n",
            "[0m 29s] Epoch 27 [7680/13374] loss=0.00023731217176343005\n",
            "[0m 29s] Epoch 27 [10240/13374] loss=0.00024549275294702964\n",
            "[0m 29s] Epoch 27 [12800/13374] loss=0.00026368862920207904\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5617/6700 83.84%\n",
            "[0m 30s] Epoch 28 [2560/13374] loss=0.00023741622426314278\n",
            "[0m 30s] Epoch 28 [5120/13374] loss=0.00023186605321825481\n",
            "[0m 30s] Epoch 28 [7680/13374] loss=0.0002476513652557818\n",
            "[0m 30s] Epoch 28 [10240/13374] loss=0.00025824391886999367\n",
            "[0m 30s] Epoch 28 [12800/13374] loss=0.0002561527190846391\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5629/6700 84.01%\n",
            "[0m 31s] Epoch 29 [2560/13374] loss=0.0002310731782927178\n",
            "[0m 31s] Epoch 29 [5120/13374] loss=0.0002466688143613283\n",
            "[0m 31s] Epoch 29 [7680/13374] loss=0.00025599238288123163\n",
            "[0m 31s] Epoch 29 [10240/13374] loss=0.00025549682904966173\n",
            "[0m 32s] Epoch 29 [12800/13374] loss=0.00025636965336161665\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5648/6700 84.30%\n",
            "[0m 32s] Epoch 30 [2560/13374] loss=0.00020456194688449613\n",
            "[0m 32s] Epoch 30 [5120/13374] loss=0.00021919556784268934\n",
            "[0m 32s] Epoch 30 [7680/13374] loss=0.00022882261328049935\n",
            "[0m 33s] Epoch 30 [10240/13374] loss=0.00023536148055427474\n",
            "[0m 33s] Epoch 30 [12800/13374] loss=0.00024345824451302178\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5612/6700 83.76%\n",
            "[0m 33s] Epoch 31 [2560/13374] loss=0.0001860817676060833\n",
            "[0m 33s] Epoch 31 [5120/13374] loss=0.00019937847173423506\n",
            "[0m 33s] Epoch 31 [7680/13374] loss=0.00020955332947778516\n",
            "[0m 34s] Epoch 31 [10240/13374] loss=0.00022640159349975874\n",
            "[0m 34s] Epoch 31 [12800/13374] loss=0.0002355823894322384\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5646/6700 84.27%\n",
            "[0m 34s] Epoch 32 [2560/13374] loss=0.000183746653056005\n",
            "[0m 34s] Epoch 32 [5120/13374] loss=0.00021627486821671483\n",
            "[0m 35s] Epoch 32 [7680/13374] loss=0.0002233822837297339\n",
            "[0m 35s] Epoch 32 [10240/13374] loss=0.00022884517657075775\n",
            "[0m 35s] Epoch 32 [12800/13374] loss=0.00023507789548602887\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5608/6700 83.70%\n",
            "[0m 35s] Epoch 33 [2560/13374] loss=0.00016573405955568887\n",
            "[0m 35s] Epoch 33 [5120/13374] loss=0.00017602240150154102\n",
            "[0m 36s] Epoch 33 [7680/13374] loss=0.0001901305991244347\n",
            "[0m 36s] Epoch 33 [10240/13374] loss=0.0002137595367457834\n",
            "[0m 36s] Epoch 33 [12800/13374] loss=0.00022435262726503425\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5635/6700 84.10%\n",
            "[0m 36s] Epoch 34 [2560/13374] loss=0.00019101457000942902\n",
            "[0m 37s] Epoch 34 [5120/13374] loss=0.00020439515355974436\n",
            "[0m 37s] Epoch 34 [7680/13374] loss=0.00021848572214366868\n",
            "[0m 37s] Epoch 34 [10240/13374] loss=0.0002164172654374852\n",
            "[0m 37s] Epoch 34 [12800/13374] loss=0.00021445222359034233\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5611/6700 83.75%\n",
            "[0m 38s] Epoch 35 [2560/13374] loss=0.0001740766929287929\n",
            "[0m 38s] Epoch 35 [5120/13374] loss=0.00020896684254694263\n",
            "[0m 38s] Epoch 35 [7680/13374] loss=0.00020893609786677795\n",
            "[0m 38s] Epoch 35 [10240/13374] loss=0.00021325330944819144\n",
            "[0m 38s] Epoch 35 [12800/13374] loss=0.00022348755315761083\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5634/6700 84.09%\n",
            "[0m 39s] Epoch 36 [2560/13374] loss=0.00019897909733117557\n",
            "[0m 39s] Epoch 36 [5120/13374] loss=0.0001981331854040036\n",
            "[0m 39s] Epoch 36 [7680/13374] loss=0.000209023409843212\n",
            "[0m 39s] Epoch 36 [10240/13374] loss=0.00020625609176931902\n",
            "[0m 39s] Epoch 36 [12800/13374] loss=0.00021201340176048688\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5630/6700 84.03%\n",
            "[0m 40s] Epoch 37 [2560/13374] loss=0.00017265303613385187\n",
            "[0m 40s] Epoch 37 [5120/13374] loss=0.00017820517969084903\n",
            "[0m 40s] Epoch 37 [7680/13374] loss=0.00019770914368564264\n",
            "[0m 40s] Epoch 37 [10240/13374] loss=0.00020195719043840653\n",
            "[0m 40s] Epoch 37 [12800/13374] loss=0.00020399074332090096\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5636/6700 84.12%\n",
            "[0m 41s] Epoch 38 [2560/13374] loss=0.00015392291970783845\n",
            "[0m 41s] Epoch 38 [5120/13374] loss=0.00018158443381253165\n",
            "[0m 41s] Epoch 38 [7680/13374] loss=0.00018538600197643974\n",
            "[0m 41s] Epoch 38 [10240/13374] loss=0.00019247945783718023\n",
            "[0m 42s] Epoch 38 [12800/13374] loss=0.00020148498922935686\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5641/6700 84.19%\n",
            "[0m 42s] Epoch 39 [2560/13374] loss=0.0001691457349807024\n",
            "[0m 42s] Epoch 39 [5120/13374] loss=0.00018059106805594637\n",
            "[0m 42s] Epoch 39 [7680/13374] loss=0.00019142830715281888\n",
            "[0m 42s] Epoch 39 [10240/13374] loss=0.0002002599014303996\n",
            "[0m 43s] Epoch 39 [12800/13374] loss=0.0002095196103618946\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5613/6700 83.78%\n",
            "[0m 43s] Epoch 40 [2560/13374] loss=0.00015334347262978553\n",
            "[0m 43s] Epoch 40 [5120/13374] loss=0.00015928634311421775\n",
            "[0m 43s] Epoch 40 [7680/13374] loss=0.00016936769352469128\n",
            "[0m 44s] Epoch 40 [10240/13374] loss=0.00017551972678120364\n",
            "[0m 44s] Epoch 40 [12800/13374] loss=0.00019625525259471034\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5625/6700 83.96%\n",
            "[0m 44s] Epoch 41 [2560/13374] loss=0.00017169596467283554\n",
            "[0m 44s] Epoch 41 [5120/13374] loss=0.00016635566316836048\n",
            "[0m 44s] Epoch 41 [7680/13374] loss=0.0001644095405936241\n",
            "[0m 45s] Epoch 41 [10240/13374] loss=0.00017841660010162741\n",
            "[0m 45s] Epoch 41 [12800/13374] loss=0.00019198759808205067\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5631/6700 84.04%\n",
            "[0m 45s] Epoch 42 [2560/13374] loss=0.00015647308828192763\n",
            "[0m 45s] Epoch 42 [5120/13374] loss=0.00017132820285041815\n",
            "[0m 46s] Epoch 42 [7680/13374] loss=0.00017579462413171618\n",
            "[0m 46s] Epoch 42 [10240/13374] loss=0.00017569509454915533\n",
            "[0m 46s] Epoch 42 [12800/13374] loss=0.00019030890791327693\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5617/6700 83.84%\n",
            "[0m 46s] Epoch 43 [2560/13374] loss=0.00015288329959730617\n",
            "[0m 47s] Epoch 43 [5120/13374] loss=0.00015809420037840027\n",
            "[0m 47s] Epoch 43 [7680/13374] loss=0.00017569078166464655\n",
            "[0m 47s] Epoch 43 [10240/13374] loss=0.00018329496178921546\n",
            "[0m 47s] Epoch 43 [12800/13374] loss=0.00018834086396964266\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5615/6700 83.81%\n",
            "[0m 47s] Epoch 44 [2560/13374] loss=0.00013802617031615226\n",
            "[0m 48s] Epoch 44 [5120/13374] loss=0.00016104235073726158\n",
            "[0m 48s] Epoch 44 [7680/13374] loss=0.0001773669891311632\n",
            "[0m 48s] Epoch 44 [10240/13374] loss=0.00017867223841676604\n",
            "[0m 48s] Epoch 44 [12800/13374] loss=0.00018362214213993867\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5626/6700 83.97%\n",
            "[0m 49s] Epoch 45 [2560/13374] loss=0.00013816238642903045\n",
            "[0m 49s] Epoch 45 [5120/13374] loss=0.00014799380896874937\n",
            "[0m 49s] Epoch 45 [7680/13374] loss=0.00016224836714779183\n",
            "[0m 49s] Epoch 45 [10240/13374] loss=0.00018152165021092514\n",
            "[0m 49s] Epoch 45 [12800/13374] loss=0.00018894679968070705\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5625/6700 83.96%\n",
            "[0m 50s] Epoch 46 [2560/13374] loss=0.00012791095286956988\n",
            "[0m 50s] Epoch 46 [5120/13374] loss=0.00014995260462455918\n",
            "[0m 50s] Epoch 46 [7680/13374] loss=0.00016721891345999513\n",
            "[0m 50s] Epoch 46 [10240/13374] loss=0.00017154192428279203\n",
            "[0m 50s] Epoch 46 [12800/13374] loss=0.00018100249813869597\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5634/6700 84.09%\n",
            "[0m 51s] Epoch 47 [2560/13374] loss=0.00014706162473885343\n",
            "[0m 51s] Epoch 47 [5120/13374] loss=0.00015938228352752049\n",
            "[0m 51s] Epoch 47 [7680/13374] loss=0.00016995575254744228\n",
            "[0m 51s] Epoch 47 [10240/13374] loss=0.00017735588535288115\n",
            "[0m 52s] Epoch 47 [12800/13374] loss=0.00018523543578339742\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5635/6700 84.10%\n",
            "[0m 52s] Epoch 48 [2560/13374] loss=0.00014179035351844505\n",
            "[0m 52s] Epoch 48 [5120/13374] loss=0.000150457325798925\n",
            "[0m 52s] Epoch 48 [7680/13374] loss=0.00016301986058048595\n",
            "[0m 52s] Epoch 48 [10240/13374] loss=0.0001723387633319362\n",
            "[0m 53s] Epoch 48 [12800/13374] loss=0.00017867292757728137\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5614/6700 83.79%\n",
            "[0m 53s] Epoch 49 [2560/13374] loss=0.0001633742664125748\n",
            "[0m 53s] Epoch 49 [5120/13374] loss=0.00014763633298571223\n",
            "[0m 53s] Epoch 49 [7680/13374] loss=0.00015602557881114383\n",
            "[0m 54s] Epoch 49 [10240/13374] loss=0.00016364371549570933\n",
            "[0m 54s] Epoch 49 [12800/13374] loss=0.00018354622094193473\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5632/6700 84.06%\n",
            "[0m 54s] Epoch 50 [2560/13374] loss=0.00015333068658947014\n",
            "[0m 54s] Epoch 50 [5120/13374] loss=0.00014336432668642373\n",
            "[0m 54s] Epoch 50 [7680/13374] loss=0.00015887790420189655\n",
            "[0m 55s] Epoch 50 [10240/13374] loss=0.00017466444778619917\n",
            "[0m 55s] Epoch 50 [12800/13374] loss=0.00018324866898183245\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5622/6700 83.91%\n",
            "[0m 55s] Epoch 51 [2560/13374] loss=0.00014506817096844317\n",
            "[0m 55s] Epoch 51 [5120/13374] loss=0.0001548668478790205\n",
            "[0m 56s] Epoch 51 [7680/13374] loss=0.0001672252306889277\n",
            "[0m 56s] Epoch 51 [10240/13374] loss=0.0001780580370905227\n",
            "[0m 56s] Epoch 51 [12800/13374] loss=0.0001816234392754268\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5610/6700 83.73%\n",
            "[0m 56s] Epoch 52 [2560/13374] loss=0.0001576350441609975\n",
            "[0m 56s] Epoch 52 [5120/13374] loss=0.000143976785329869\n",
            "[0m 57s] Epoch 52 [7680/13374] loss=0.00015328547403138751\n",
            "[0m 57s] Epoch 52 [10240/13374] loss=0.00016527092084288596\n",
            "[0m 57s] Epoch 52 [12800/13374] loss=0.00017453912369091995\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5624/6700 83.94%\n",
            "[0m 57s] Epoch 53 [2560/13374] loss=0.0001732815864670556\n",
            "[0m 58s] Epoch 53 [5120/13374] loss=0.00016889488106244243\n",
            "[0m 58s] Epoch 53 [7680/13374] loss=0.00017804209516422513\n",
            "[0m 58s] Epoch 53 [10240/13374] loss=0.0001741634641348355\n",
            "[0m 58s] Epoch 53 [12800/13374] loss=0.00017931473801581887\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5622/6700 83.91%\n",
            "[0m 58s] Epoch 54 [2560/13374] loss=0.00014337110696942544\n",
            "[0m 59s] Epoch 54 [5120/13374] loss=0.00014599171281588498\n",
            "[0m 59s] Epoch 54 [7680/13374] loss=0.00015805443605737917\n",
            "[0m 59s] Epoch 54 [10240/13374] loss=0.00016717362059353035\n",
            "[0m 59s] Epoch 54 [12800/13374] loss=0.00017203576404426713\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5639/6700 84.16%\n",
            "[1m 0s] Epoch 55 [2560/13374] loss=0.00015949270964483732\n",
            "[1m 0s] Epoch 55 [5120/13374] loss=0.00015893412783043459\n",
            "[1m 0s] Epoch 55 [7680/13374] loss=0.0001560376571433153\n",
            "[1m 0s] Epoch 55 [10240/13374] loss=0.00017271630040340824\n",
            "[1m 0s] Epoch 55 [12800/13374] loss=0.00017463530704844743\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5626/6700 83.97%\n",
            "[1m 1s] Epoch 56 [2560/13374] loss=0.00014685683490824885\n",
            "[1m 1s] Epoch 56 [5120/13374] loss=0.00014350629317050334\n",
            "[1m 1s] Epoch 56 [7680/13374] loss=0.00015828180112293922\n",
            "[1m 1s] Epoch 56 [10240/13374] loss=0.00016301093328365823\n",
            "[1m 1s] Epoch 56 [12800/13374] loss=0.0001729814753343817\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5630/6700 84.03%\n",
            "[1m 2s] Epoch 57 [2560/13374] loss=0.00013902124846936202\n",
            "[1m 2s] Epoch 57 [5120/13374] loss=0.00014807240695517975\n",
            "[1m 2s] Epoch 57 [7680/13374] loss=0.00016411212491220794\n",
            "[1m 2s] Epoch 57 [10240/13374] loss=0.00016404722882725764\n",
            "[1m 2s] Epoch 57 [12800/13374] loss=0.00016901849332498386\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5640/6700 84.18%\n",
            "[1m 3s] Epoch 58 [2560/13374] loss=0.00013251284472062252\n",
            "[1m 3s] Epoch 58 [5120/13374] loss=0.0001370725080050761\n",
            "[1m 3s] Epoch 58 [7680/13374] loss=0.0001413369604658025\n",
            "[1m 3s] Epoch 58 [10240/13374] loss=0.00015725643679616043\n",
            "[1m 4s] Epoch 58 [12800/13374] loss=0.00016823953483253719\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5641/6700 84.19%\n",
            "[1m 4s] Epoch 59 [2560/13374] loss=0.00013768081553280353\n",
            "[1m 4s] Epoch 59 [5120/13374] loss=0.00012813271478080425\n",
            "[1m 4s] Epoch 59 [7680/13374] loss=0.0001454238317819545\n",
            "[1m 5s] Epoch 59 [10240/13374] loss=0.00016087115136542707\n",
            "[1m 5s] Epoch 59 [12800/13374] loss=0.00016871012827323283\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5622/6700 83.91%\n",
            "[1m 5s] Epoch 60 [2560/13374] loss=0.00014020774033269846\n",
            "[1m 5s] Epoch 60 [5120/13374] loss=0.00015131733125599566\n",
            "[1m 5s] Epoch 60 [7680/13374] loss=0.00016056433378253132\n",
            "[1m 6s] Epoch 60 [10240/13374] loss=0.00016767927700129804\n",
            "[1m 6s] Epoch 60 [12800/13374] loss=0.00016920147070777602\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5630/6700 84.03%\n",
            "[1m 6s] Epoch 61 [2560/13374] loss=0.00014095390506554394\n",
            "[1m 6s] Epoch 61 [5120/13374] loss=0.00015276791637006682\n",
            "[1m 7s] Epoch 61 [7680/13374] loss=0.00016062638557438427\n",
            "[1m 7s] Epoch 61 [10240/13374] loss=0.00016451022838737117\n",
            "[1m 7s] Epoch 61 [12800/13374] loss=0.00016749384376453237\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5624/6700 83.94%\n",
            "[1m 7s] Epoch 62 [2560/13374] loss=0.00012188472028356046\n",
            "[1m 7s] Epoch 62 [5120/13374] loss=0.00013255774047138402\n",
            "[1m 8s] Epoch 62 [7680/13374] loss=0.00014282523588917683\n",
            "[1m 8s] Epoch 62 [10240/13374] loss=0.00015167938336162478\n",
            "[1m 8s] Epoch 62 [12800/13374] loss=0.00016090269818960223\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5633/6700 84.07%\n",
            "[1m 8s] Epoch 63 [2560/13374] loss=0.0001428128503903281\n",
            "[1m 9s] Epoch 63 [5120/13374] loss=0.00012733217736240476\n",
            "[1m 9s] Epoch 63 [7680/13374] loss=0.0001452899494324811\n",
            "[1m 9s] Epoch 63 [10240/13374] loss=0.0001548575704873656\n",
            "[1m 9s] Epoch 63 [12800/13374] loss=0.00016386270697694272\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5621/6700 83.90%\n",
            "[1m 9s] Epoch 64 [2560/13374] loss=0.00013942422592663206\n",
            "[1m 10s] Epoch 64 [5120/13374] loss=0.00014814032219874208\n",
            "[1m 10s] Epoch 64 [7680/13374] loss=0.00014887938668834978\n",
            "[1m 10s] Epoch 64 [10240/13374] loss=0.0001590006899277796\n",
            "[1m 10s] Epoch 64 [12800/13374] loss=0.0001634471895522438\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5651/6700 84.34%\n",
            "[1m 11s] Epoch 65 [2560/13374] loss=0.00011399077557143756\n",
            "[1m 11s] Epoch 65 [5120/13374] loss=0.00013755745785601903\n",
            "[1m 11s] Epoch 65 [7680/13374] loss=0.0001470545117626898\n",
            "[1m 11s] Epoch 65 [10240/13374] loss=0.00016017786401789635\n",
            "[1m 11s] Epoch 65 [12800/13374] loss=0.00016498100419994443\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5640/6700 84.18%\n",
            "[1m 12s] Epoch 66 [2560/13374] loss=0.0001451254400308244\n",
            "[1m 12s] Epoch 66 [5120/13374] loss=0.0001462566084228456\n",
            "[1m 12s] Epoch 66 [7680/13374] loss=0.00015650466860582432\n",
            "[1m 12s] Epoch 66 [10240/13374] loss=0.00015570919640595093\n",
            "[1m 12s] Epoch 66 [12800/13374] loss=0.00016241907709627413\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5622/6700 83.91%\n",
            "[1m 13s] Epoch 67 [2560/13374] loss=0.00012243170058354736\n",
            "[1m 13s] Epoch 67 [5120/13374] loss=0.00013788736068818253\n",
            "[1m 13s] Epoch 67 [7680/13374] loss=0.00014087885429034941\n",
            "[1m 13s] Epoch 67 [10240/13374] loss=0.00015386836839752504\n",
            "[1m 13s] Epoch 67 [12800/13374] loss=0.00016656432970194146\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5614/6700 83.79%\n",
            "[1m 14s] Epoch 68 [2560/13374] loss=0.00015374272225017195\n",
            "[1m 14s] Epoch 68 [5120/13374] loss=0.00015663890499126865\n",
            "[1m 14s] Epoch 68 [7680/13374] loss=0.00015677442776601918\n",
            "[1m 14s] Epoch 68 [10240/13374] loss=0.0001579133159793855\n",
            "[1m 15s] Epoch 68 [12800/13374] loss=0.00016758367193688172\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5627/6700 83.99%\n",
            "[1m 15s] Epoch 69 [2560/13374] loss=0.0001653574283409398\n",
            "[1m 15s] Epoch 69 [5120/13374] loss=0.00014116688962531043\n",
            "[1m 15s] Epoch 69 [7680/13374] loss=0.00015031917440258742\n",
            "[1m 15s] Epoch 69 [10240/13374] loss=0.00015526188535659459\n",
            "[1m 16s] Epoch 69 [12800/13374] loss=0.00015659086559026037\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5626/6700 83.97%\n",
            "[1m 16s] Epoch 70 [2560/13374] loss=0.00011666380560200195\n",
            "[1m 16s] Epoch 70 [5120/13374] loss=0.00011842530166177312\n",
            "[1m 16s] Epoch 70 [7680/13374] loss=0.00012388476886068627\n",
            "[1m 17s] Epoch 70 [10240/13374] loss=0.0001428463037882466\n",
            "[1m 17s] Epoch 70 [12800/13374] loss=0.00015947459818562492\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5609/6700 83.72%\n",
            "[1m 17s] Epoch 71 [2560/13374] loss=0.0001222655475430656\n",
            "[1m 17s] Epoch 71 [5120/13374] loss=0.0001245865729288198\n",
            "[1m 17s] Epoch 71 [7680/13374] loss=0.00013227963014893855\n",
            "[1m 18s] Epoch 71 [10240/13374] loss=0.00014210060726327356\n",
            "[1m 18s] Epoch 71 [12800/13374] loss=0.00015663174825021996\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5615/6700 83.81%\n",
            "[1m 18s] Epoch 72 [2560/13374] loss=0.00012720510349026882\n",
            "[1m 18s] Epoch 72 [5120/13374] loss=0.0001402224206685787\n",
            "[1m 19s] Epoch 72 [7680/13374] loss=0.0001423638167276901\n",
            "[1m 19s] Epoch 72 [10240/13374] loss=0.0001513301117483934\n",
            "[1m 19s] Epoch 72 [12800/13374] loss=0.00016016576868423726\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5627/6700 83.99%\n",
            "[1m 19s] Epoch 73 [2560/13374] loss=0.00013044983788859099\n",
            "[1m 20s] Epoch 73 [5120/13374] loss=0.00013301517174113542\n",
            "[1m 20s] Epoch 73 [7680/13374] loss=0.000150533817698791\n",
            "[1m 20s] Epoch 73 [10240/13374] loss=0.00014931374826119282\n",
            "[1m 20s] Epoch 73 [12800/13374] loss=0.00015830526943318545\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5628/6700 84.00%\n",
            "[1m 20s] Epoch 74 [2560/13374] loss=0.00011536961974343286\n",
            "[1m 21s] Epoch 74 [5120/13374] loss=0.00012211540288262768\n",
            "[1m 21s] Epoch 74 [7680/13374] loss=0.00012667983185868554\n",
            "[1m 21s] Epoch 74 [10240/13374] loss=0.00013530206624636775\n",
            "[1m 21s] Epoch 74 [12800/13374] loss=0.00014991495925642084\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5612/6700 83.76%\n",
            "[1m 22s] Epoch 75 [2560/13374] loss=0.00014115453086560592\n",
            "[1m 22s] Epoch 75 [5120/13374] loss=0.00014510145592794288\n",
            "[1m 22s] Epoch 75 [7680/13374] loss=0.0001529015552174921\n",
            "[1m 22s] Epoch 75 [10240/13374] loss=0.00015410168543894542\n",
            "[1m 22s] Epoch 75 [12800/13374] loss=0.00015633438313670923\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5623/6700 83.93%\n",
            "[1m 23s] Epoch 76 [2560/13374] loss=0.00013986897174618208\n",
            "[1m 23s] Epoch 76 [5120/13374] loss=0.00013704524717468304\n",
            "[1m 23s] Epoch 76 [7680/13374] loss=0.00014848448190605268\n",
            "[1m 23s] Epoch 76 [10240/13374] loss=0.00014666351798950928\n",
            "[1m 23s] Epoch 76 [12800/13374] loss=0.00015353615432104562\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5635/6700 84.10%\n",
            "[1m 24s] Epoch 77 [2560/13374] loss=0.00013795932536595502\n",
            "[1m 24s] Epoch 77 [5120/13374] loss=0.00013998804170114453\n",
            "[1m 24s] Epoch 77 [7680/13374] loss=0.00014868563133253095\n",
            "[1m 24s] Epoch 77 [10240/13374] loss=0.0001493791878601769\n",
            "[1m 24s] Epoch 77 [12800/13374] loss=0.0001534965580503922\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5642/6700 84.21%\n",
            "[1m 25s] Epoch 78 [2560/13374] loss=0.00012432695330062417\n",
            "[1m 25s] Epoch 78 [5120/13374] loss=0.0001309366221903474\n",
            "[1m 25s] Epoch 78 [7680/13374] loss=0.00014125706208384752\n",
            "[1m 25s] Epoch 78 [10240/13374] loss=0.00015073945787662523\n",
            "[1m 26s] Epoch 78 [12800/13374] loss=0.0001535964759386843\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5605/6700 83.66%\n",
            "[1m 26s] Epoch 79 [2560/13374] loss=0.00013268862530821935\n",
            "[1m 26s] Epoch 79 [5120/13374] loss=0.00013440646689559798\n",
            "[1m 26s] Epoch 79 [7680/13374] loss=0.00014272208597200612\n",
            "[1m 26s] Epoch 79 [10240/13374] loss=0.0001496312877861783\n",
            "[1m 27s] Epoch 79 [12800/13374] loss=0.00015276703183189966\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5624/6700 83.94%\n",
            "[1m 27s] Epoch 80 [2560/13374] loss=0.00013445584918372333\n",
            "[1m 27s] Epoch 80 [5120/13374] loss=0.00013086233357171296\n",
            "[1m 27s] Epoch 80 [7680/13374] loss=0.00013811011679839189\n",
            "[1m 28s] Epoch 80 [10240/13374] loss=0.00014630557134296396\n",
            "[1m 28s] Epoch 80 [12800/13374] loss=0.0001531290863204049\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5623/6700 83.93%\n",
            "[1m 28s] Epoch 81 [2560/13374] loss=0.00010571829552645795\n",
            "[1m 28s] Epoch 81 [5120/13374] loss=0.0001350725993688684\n",
            "[1m 28s] Epoch 81 [7680/13374] loss=0.00014305125732789749\n",
            "[1m 29s] Epoch 81 [10240/13374] loss=0.00014284088547356077\n",
            "[1m 29s] Epoch 81 [12800/13374] loss=0.00015610101887432394\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5623/6700 83.93%\n",
            "[1m 29s] Epoch 82 [2560/13374] loss=0.00011316509735479486\n",
            "[1m 29s] Epoch 82 [5120/13374] loss=0.00012195781509944936\n",
            "[1m 30s] Epoch 82 [7680/13374] loss=0.0001380469784635352\n",
            "[1m 30s] Epoch 82 [10240/13374] loss=0.00014078288886594238\n",
            "[1m 30s] Epoch 82 [12800/13374] loss=0.00015067055013787467\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5615/6700 83.81%\n",
            "[1m 30s] Epoch 83 [2560/13374] loss=0.00013423310083453542\n",
            "[1m 31s] Epoch 83 [5120/13374] loss=0.0001268395759325358\n",
            "[1m 31s] Epoch 83 [7680/13374] loss=0.00013063637707091402\n",
            "[1m 31s] Epoch 83 [10240/13374] loss=0.0001361532938062737\n",
            "[1m 31s] Epoch 83 [12800/13374] loss=0.0001511613999173278\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5625/6700 83.96%\n",
            "[1m 31s] Epoch 84 [2560/13374] loss=0.0001330508202954661\n",
            "[1m 32s] Epoch 84 [5120/13374] loss=0.00013069575979898218\n",
            "[1m 32s] Epoch 84 [7680/13374] loss=0.00014199375630899642\n",
            "[1m 32s] Epoch 84 [10240/13374] loss=0.00014573670841855346\n",
            "[1m 32s] Epoch 84 [12800/13374] loss=0.0001502235648513306\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5618/6700 83.85%\n",
            "[1m 33s] Epoch 85 [2560/13374] loss=0.00012730015259876382\n",
            "[1m 33s] Epoch 85 [5120/13374] loss=0.00014329391760838916\n",
            "[1m 33s] Epoch 85 [7680/13374] loss=0.0001417531574285628\n",
            "[1m 33s] Epoch 85 [10240/13374] loss=0.00014548362182722485\n",
            "[1m 33s] Epoch 85 [12800/13374] loss=0.00015139175771764713\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5614/6700 83.79%\n",
            "[1m 34s] Epoch 86 [2560/13374] loss=0.0001096244050131645\n",
            "[1m 34s] Epoch 86 [5120/13374] loss=0.000117618916920037\n",
            "[1m 34s] Epoch 86 [7680/13374] loss=0.00013484652711971042\n",
            "[1m 34s] Epoch 86 [10240/13374] loss=0.00014459910435107303\n",
            "[1m 34s] Epoch 86 [12800/13374] loss=0.00014960257307393475\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5624/6700 83.94%\n",
            "[1m 35s] Epoch 87 [2560/13374] loss=0.00014100743283051997\n",
            "[1m 35s] Epoch 87 [5120/13374] loss=0.00012777037227351684\n",
            "[1m 35s] Epoch 87 [7680/13374] loss=0.0001364717238175217\n",
            "[1m 35s] Epoch 87 [10240/13374] loss=0.0001447282025765162\n",
            "[1m 35s] Epoch 87 [12800/13374] loss=0.00014975824306020513\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5629/6700 84.01%\n",
            "[1m 36s] Epoch 88 [2560/13374] loss=9.86093727988191e-05\n",
            "[1m 36s] Epoch 88 [5120/13374] loss=0.00011196166087756865\n",
            "[1m 36s] Epoch 88 [7680/13374] loss=0.00012632504488768365\n",
            "[1m 36s] Epoch 88 [10240/13374] loss=0.00013744948100793408\n",
            "[1m 36s] Epoch 88 [12800/13374] loss=0.000147611515421886\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5625/6700 83.96%\n",
            "[1m 37s] Epoch 89 [2560/13374] loss=0.00010171375979552976\n",
            "[1m 37s] Epoch 89 [5120/13374] loss=0.0001245204133738298\n",
            "[1m 37s] Epoch 89 [7680/13374] loss=0.00013412770325279175\n",
            "[1m 37s] Epoch 89 [10240/13374] loss=0.00013442560493786003\n",
            "[1m 38s] Epoch 89 [12800/13374] loss=0.0001466702516336227\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5614/6700 83.79%\n",
            "[1m 38s] Epoch 90 [2560/13374] loss=0.0001042765892634634\n",
            "[1m 38s] Epoch 90 [5120/13374] loss=0.00011830862895294559\n",
            "[1m 38s] Epoch 90 [7680/13374] loss=0.00012487932520646912\n",
            "[1m 38s] Epoch 90 [10240/13374] loss=0.00013903269045840717\n",
            "[1m 39s] Epoch 90 [12800/13374] loss=0.00014987413458584343\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5626/6700 83.97%\n",
            "[1m 39s] Epoch 91 [2560/13374] loss=0.0001433963938325178\n",
            "[1m 39s] Epoch 91 [5120/13374] loss=0.0001357089393422939\n",
            "[1m 39s] Epoch 91 [7680/13374] loss=0.00014373918917650978\n",
            "[1m 40s] Epoch 91 [10240/13374] loss=0.0001447234066290548\n",
            "[1m 40s] Epoch 91 [12800/13374] loss=0.00014754573072423227\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5632/6700 84.06%\n",
            "[1m 40s] Epoch 92 [2560/13374] loss=0.00012590053156600334\n",
            "[1m 40s] Epoch 92 [5120/13374] loss=0.00012981141298951115\n",
            "[1m 41s] Epoch 92 [7680/13374] loss=0.00013074885355308653\n",
            "[1m 41s] Epoch 92 [10240/13374] loss=0.00013787350926577346\n",
            "[1m 41s] Epoch 92 [12800/13374] loss=0.00014643858638009987\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5613/6700 83.78%\n",
            "[1m 41s] Epoch 93 [2560/13374] loss=0.00010485781858733389\n",
            "[1m 41s] Epoch 93 [5120/13374] loss=0.00011403938278817805\n",
            "[1m 42s] Epoch 93 [7680/13374] loss=0.00013435045802907554\n",
            "[1m 42s] Epoch 93 [10240/13374] loss=0.00013742369710598724\n",
            "[1m 42s] Epoch 93 [12800/13374] loss=0.00014628015844209586\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5622/6700 83.91%\n",
            "[1m 42s] Epoch 94 [2560/13374] loss=0.00013119044597260655\n",
            "[1m 43s] Epoch 94 [5120/13374] loss=0.0001373058108583791\n",
            "[1m 43s] Epoch 94 [7680/13374] loss=0.00013524449944573764\n",
            "[1m 43s] Epoch 94 [10240/13374] loss=0.0001403465106704971\n",
            "[1m 43s] Epoch 94 [12800/13374] loss=0.00014295812448835931\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5613/6700 83.78%\n",
            "[1m 43s] Epoch 95 [2560/13374] loss=9.432138358533848e-05\n",
            "[1m 44s] Epoch 95 [5120/13374] loss=0.00011611115442065057\n",
            "[1m 44s] Epoch 95 [7680/13374] loss=0.00012337269266330015\n",
            "[1m 44s] Epoch 95 [10240/13374] loss=0.00013239851250546053\n",
            "[1m 44s] Epoch 95 [12800/13374] loss=0.00014184471423504873\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5621/6700 83.90%\n",
            "[1m 45s] Epoch 96 [2560/13374] loss=0.00012218804586154873\n",
            "[1m 45s] Epoch 96 [5120/13374] loss=0.0001327636802670895\n",
            "[1m 45s] Epoch 96 [7680/13374] loss=0.0001358356763375923\n",
            "[1m 45s] Epoch 96 [10240/13374] loss=0.00014036091870366362\n",
            "[1m 45s] Epoch 96 [12800/13374] loss=0.00014746821820153853\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5607/6700 83.69%\n",
            "[1m 46s] Epoch 97 [2560/13374] loss=0.00012361813605821226\n",
            "[1m 46s] Epoch 97 [5120/13374] loss=0.0001332166621068609\n",
            "[1m 46s] Epoch 97 [7680/13374] loss=0.0001369643373133537\n",
            "[1m 46s] Epoch 97 [10240/13374] loss=0.000143115010632755\n",
            "[1m 46s] Epoch 97 [12800/13374] loss=0.00014606032527808566\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5620/6700 83.88%\n",
            "[1m 47s] Epoch 98 [2560/13374] loss=0.00013687867103726604\n",
            "[1m 47s] Epoch 98 [5120/13374] loss=0.00013939822565589566\n",
            "[1m 47s] Epoch 98 [7680/13374] loss=0.00014196188009615678\n",
            "[1m 47s] Epoch 98 [10240/13374] loss=0.00014590714090445545\n",
            "[1m 47s] Epoch 98 [12800/13374] loss=0.00014651503748609686\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5626/6700 83.97%\n",
            "[1m 48s] Epoch 99 [2560/13374] loss=0.0001422344175807666\n",
            "[1m 48s] Epoch 99 [5120/13374] loss=0.00013453698993544095\n",
            "[1m 48s] Epoch 99 [7680/13374] loss=0.00013705932409114515\n",
            "[1m 48s] Epoch 99 [10240/13374] loss=0.0001431731599041086\n",
            "[1m 48s] Epoch 99 [12800/13374] loss=0.00014266782942286228\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5617/6700 83.84%\n",
            "[1m 49s] Epoch 100 [2560/13374] loss=0.00012309165067563298\n",
            "[1m 49s] Epoch 100 [5120/13374] loss=0.00012632582383957923\n",
            "[1m 49s] Epoch 100 [7680/13374] loss=0.0001285453083255561\n",
            "[1m 49s] Epoch 100 [10240/13374] loss=0.0001411149629348074\n",
            "[1m 50s] Epoch 100 [12800/13374] loss=0.00014315860971692018\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5620/6700 83.88%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}