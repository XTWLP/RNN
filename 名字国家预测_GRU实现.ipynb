{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "名字国家预测 GRU实现.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/XTWLP/RNN/blob/main/%E5%90%8D%E5%AD%97%E5%9B%BD%E5%AE%B6%E9%A2%84%E6%B5%8B_GRU%E5%AE%9E%E7%8E%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEI1GfvO65dN"
      },
      "source": [
        "import gzip\n",
        "import csv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from torchvision import datasets\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import math\n",
        "\n",
        "class NameDataset(Dataset):\n",
        "    def __init__(self, is_train_set=True):\n",
        "        filename = 'names_train.csv.gz' if is_train_set else 'names_test.csv.gz'\n",
        "        with gzip.open(filename, 'rt') as f:\n",
        "            reader = csv.reader(f)\n",
        "            rows = list(reader)\n",
        "        self.names = [row[0] for row in rows]\n",
        "        self.len = len(self.names)\n",
        "        self.countries = [row[1] for row in rows]\n",
        "        self.country_list = list(sorted(set(self.countries)))\n",
        "        self.country_dict = self.getCountryDict()\n",
        "        self.country_num = len(self.country_list)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return self.names[index], self.country_dict[self.countries[index]]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.len\n",
        "    \n",
        "    def getCountryDict(self):\n",
        "        country_dict = dict()\n",
        "        for idx, country_name in enumerate(self.country_list, 0):\n",
        "            country_dict[country_name] = idx\n",
        "        return country_dict\n",
        "    \n",
        "    def idx2country(self, index):\n",
        "        return self.country_list[index]\n",
        "    \n",
        "    def getCountriesNum(self):\n",
        "        return self.country_num"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z81scs_965dU"
      },
      "source": [
        "class RNNClassifier(torch.nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, n_layers=1, bidirectional=True):\n",
        "            super(RNNClassifier, self).__init__()\n",
        "            self.hidden_size = hidden_size\n",
        "            self.n_layers = n_layers\n",
        "            self.n_directions = 2 if bidirectional else 1\n",
        "            \n",
        "            self.embedding = torch.nn.Embedding(input_size, hidden_size)\n",
        "            self.gru = torch.nn.GRU(hidden_size, hidden_size, n_layers,\n",
        "                                    bidirectional=bidirectional)\n",
        "            self.fc = torch.nn.Linear(hidden_size * self.n_directions, output_size)\n",
        "    \n",
        "    def _init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.n_layers * self.n_directions,\n",
        "                            batch_size, self.hidden_size)\n",
        "        return create_tensor(hidden)\n",
        "    def forward(self, input, seq_lengths):\n",
        "        # input shape : B x S -> S x B\n",
        "        input = input.t()\n",
        "        batch_size = input.size(1)\n",
        "        \n",
        "        hidden = self._init_hidden(batch_size)\n",
        "        embedding = self.embedding(input)\n",
        "        \n",
        "        # pack them up\n",
        "        gru_input = nn.utils.rnn.pack_padded_sequence(embedding, seq_lengths)\n",
        "        \n",
        "        output, hidden = self.gru(gru_input, hidden)\n",
        "        if self.n_directions == 2:\n",
        "            hidden_cat = torch.cat([hidden[-1], hidden[-2]], dim=1)\n",
        "        else:\n",
        "            hidden_cat = hidden[-1]\n",
        "        fc_output = self.fc(hidden_cat)\n",
        "        return fc_output"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i97RQ-VT65dV"
      },
      "source": [
        "def name2list(name):\n",
        "    arr = [ord(c) for c in name]\n",
        "    return arr, len(arr)\n",
        "\n",
        "def create_tensor(tensor):\n",
        "    if USE_GPU:\n",
        "        device = torch.device(\"cuda:0\")\n",
        "        tensor = tensor.to(device)\n",
        "    return tensor"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTftTRuG65dV"
      },
      "source": [
        "def make_tensors(names, countries):\n",
        "        sequences_and_lengths = [name2list(name) for name in names]\n",
        "        name_sequences = [sl[0] for sl in sequences_and_lengths]\n",
        "        seq_lengths = torch.LongTensor([sl[1] for sl in sequences_and_lengths])\n",
        "        countries = countries.long()\n",
        "\n",
        "        # make tensor of name, BatchSize x SeqLen\n",
        "        seq_tensor = torch.zeros(len(name_sequences), seq_lengths.max()).long()\n",
        "        for idx, (seq, seq_len) in enumerate(zip(name_sequences, seq_lengths), 0):\n",
        "            seq_tensor[idx, :seq_len] = torch.LongTensor(seq)\n",
        "       \n",
        "        # sort by length to use pack_padded_sequence\n",
        "        seq_lengths, perm_idx = seq_lengths.sort(dim=0, descending=True)\n",
        "        seq_tensor = seq_tensor[perm_idx]\n",
        "        countries = countries[perm_idx]\n",
        "        \n",
        "        return create_tensor(seq_tensor), \\\n",
        "                create_tensor(seq_lengths),\\\n",
        "                create_tensor(countries)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1nZszWL65dW"
      },
      "source": [
        "def trainModel():\n",
        "    total_loss = 0\n",
        "    for i, (names, countries) in enumerate(trainloader, 1):\n",
        "        inputs, seq_lengths, target = make_tensors(names, countries)\n",
        "        output = classifier(inputs, seq_lengths)\n",
        "        loss = criterion(output, target)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        if i % 10 == 0:\n",
        "            print(f'[{time_since(start)}] Epoch {epoch} ', end='')\n",
        "            print(f'[{i * len(inputs)}/{len(trainset)}] ', end='')\n",
        "            print(f'loss={total_loss / (i * len(inputs))}')\n",
        "    return total_loss"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ko4AnZ9-65dW"
      },
      "source": [
        "def testModel():\n",
        "    correct = 0\n",
        "    total = len(testset)\n",
        "    print(\"evaluating trained model ...\")\n",
        "    with torch.no_grad():\n",
        "        for i, (names, countries) in enumerate(testloader, 1):\n",
        "            inputs, seq_lengths, target = make_tensors(names, countries)\n",
        "            output = classifier(inputs, seq_lengths)\n",
        "            pred = output.max(dim=1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    \n",
        "        percent = '%.2f' % (100 * correct / total)\n",
        "        print(f'Test set: Accuracy {correct}/{total} {percent}%')\n",
        "    \n",
        "    return correct / total"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEQcd0Gj65dW"
      },
      "source": [
        "# Parameters\n",
        "HIDDEN_SIZE = 100\n",
        "BATCH_SIZE = 256\n",
        "N_LAYER = 2\n",
        "N_EPOCHS = 100\n",
        "N_CHARS = 128\n",
        "USE_GPU = False\n",
        "\n",
        "trainset = NameDataset(is_train_set=True)\n",
        "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "testset = NameDataset(is_train_set=False)\n",
        "testloader = DataLoader(testset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "N_COUNTRY = trainset.getCountriesNum()\n",
        "\n",
        "def time_since(since):\n",
        "    s = time.time() - since\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXIHO5GQ65dX",
        "outputId": "5d85688c-3f60-4a35-a87f-43778b286e18"
      },
      "source": [
        "import time as time\n",
        "if __name__ == '__main__':\n",
        "    classifier = RNNClassifier(N_CHARS, HIDDEN_SIZE, N_COUNTRY, N_LAYER)\n",
        "    if USE_GPU:\n",
        "        device = torch.device(\"cuda:0\")\n",
        "        classifier.to(device)\n",
        "        \n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(classifier.parameters(), lr=0.001)\n",
        "    \n",
        "    start = time.time()\n",
        "    print(\"Training for %d epochs...\" % N_EPOCHS)\n",
        "    acc_list = []\n",
        "    for epoch in range(1, N_EPOCHS + 1):\n",
        "        # Train cycle\n",
        "        trainModel()\n",
        "        acc = testModel()\n",
        "        acc_list.append(acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training for 100 epochs...\n",
            "[0m 1s] Epoch 1 [2560/13374] loss=0.008649419015273451\n",
            "[0m 3s] Epoch 1 [5120/13374] loss=0.007546639745123684\n",
            "[0m 4s] Epoch 1 [7680/13374] loss=0.0069094425377746425\n",
            "[0m 6s] Epoch 1 [10240/13374] loss=0.006482199358288199\n",
            "[0m 7s] Epoch 1 [12800/13374] loss=0.006098490729928016\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 4416/6700 65.91%\n",
            "[0m 10s] Epoch 2 [2560/13374] loss=0.00433320754673332\n",
            "[0m 11s] Epoch 2 [5120/13374] loss=0.0042062967433594165\n",
            "[0m 13s] Epoch 2 [7680/13374] loss=0.004057924216613174\n",
            "[0m 14s] Epoch 2 [10240/13374] loss=0.003971924143843353\n",
            "[0m 16s] Epoch 2 [12800/13374] loss=0.003899291269481182\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 4890/6700 72.99%\n",
            "[0m 18s] Epoch 3 [2560/13374] loss=0.003520940477028489\n",
            "[0m 20s] Epoch 3 [5120/13374] loss=0.003389047598466277\n",
            "[0m 21s] Epoch 3 [7680/13374] loss=0.003256725783770283\n",
            "[0m 23s] Epoch 3 [10240/13374] loss=0.0031741824408527465\n",
            "[0m 24s] Epoch 3 [12800/13374] loss=0.0030759233748540284\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5198/6700 77.58%\n",
            "[0m 27s] Epoch 4 [2560/13374] loss=0.0027763495687395333\n",
            "[0m 28s] Epoch 4 [5120/13374] loss=0.0027084029861725867\n",
            "[0m 30s] Epoch 4 [7680/13374] loss=0.002670504579630991\n",
            "[0m 31s] Epoch 4 [10240/13374] loss=0.002635092323180288\n",
            "[0m 33s] Epoch 4 [12800/13374] loss=0.0026043177908286453\n",
            "evaluating trained model ...\n",
            "Test set: Accuracy 5337/6700 79.66%\n",
            "[0m 35s] Epoch 5 [2560/13374] loss=0.0023494209512136877\n",
            "[0m 37s] Epoch 5 [5120/13374] loss=0.0023158733965829015\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}